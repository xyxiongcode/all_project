# 激进的内存优化方案

## 问题分析
即使只有18个样本，仍然出现GPU内存超限。这说明问题不在数据集大小，而是**单个样本的模型内存占用过大**。

## 单个样本的内存占用估算

### 输入数据
- RGB图像: `[1, 8, 3, 224, 224]` = ~4.8MB (FP32)
- 深度图像: `[1, 8, 1, 224, 224]` = ~1.6MB (FP32)
- **小计: ~6.4MB**

### 编码器内存（DINOv2）
- 8帧RGB编码（每帧多尺度特征）：~200-400MB
- 8帧深度编码：~200-400MB
- **小计: ~400-800MB**

### Transformer Decoder
- temporal_depth=8层，每层存储激活值：~500MB-1GB
- attention矩阵（序列长度×序列长度）：~100-200MB
- **小计: ~600-1200MB**

### 总计
**单个batch (batch_size=1) 需要: ~1-2GB GPU内存**

加上梯度、优化器状态等，实际需要**3-4GB+**。

## 激进优化方案

### 1. 减少图像分辨率（最有效）
```python
image_size=168,  # 从224减少到168（14的倍数）
```
**内存节省**: 约44%的编码器内存

### 2. 减少历史帧数
```python
memory_size=4,  # 从8减少到4
```
**内存节省**: 约50%的输入和编码器内存

### 3. 减少预测步数
```python
predict_size=12,  # 从24减少到12
```
**内存节省**: 约50%的decoder输出内存

### 4. 减少Transformer层数
```python
temporal_depth=4,  # 从8减少到4
```
**内存节省**: 约50%的Transformer内存

### 5. 减少注意力头数
```python
heads=4,  # 从8减少到4
```
**内存节省**: 约25-30%的attention内存

### 6. 减少序列长度
```python
max_seq_len=64,  # 从128减少到64
query_num=16,    # 从32减少到16
```
**内存节省**: 约50%的序列处理内存

## 推荐配置

```python
image_size=168,      # 减少编码器内存（44%节省）
memory_size=4,       # 减少输入内存（50%节省）
predict_size=12,     # 减少输出内存（50%节省）
temporal_depth=4,    # 减少Transformer内存（50%节省）
heads=4,             # 减少attention内存（30%节省）
max_seq_len=64,      # 减少序列内存（50%节省）
query_num=16,        # 减少查询内存（50%节省）
```

**预计总内存节省**: 约70-80%

## 其他优化

1. **确保使用bf16**: 已经启用
2. **确保batch_size=1**: 已经设置
3. **确保num_workers=0**: 已经设置
4. **增加内存清理频率**: 在forward中及时清理中间变量

## 如果仍然OOM

考虑：
1. 进一步减少memory_size到2
2. 进一步减少temporal_depth到2
3. 使用更小的图像尺寸（154 = 14×11）
